# Evaluating a Hypothesis

Once we have done some trouble shooting for errors in our predictions by:

* Getting more training
* Trying smaller sets of features
* Trying additional
* Trying polynomial features
* Increasing or decreasing λ

We can move on to evaluate our new hypothesis.

A hypothesis may have a low error for the training examples but still be inaccurate (because of overfitting). Thus, to evaluate a hypothesis, given a dataset of training examples, we can split up the data into two sets: a **training set** and a **test set**.

Typically, the training set consists of 70 % of ym and our data and the test set is the remaining 30 %.

The new procedure using these two sets is then:

1. Learn Θ and minimize $J_{train}(Θ)$ using the training set.
2. Compute the test set error $J_{test}(Θ)$.

The test set error

1. For linear regression: $J_{test}(Θ)=\frac1{2m_{test}}∑_{i=1}^{ m_{test}}(hΘ(x_{test}^{(i)})−y_{test}^{(i)})^2$

2. For classification ~ Misclassification error (aka 0/1 misclassification error):
$err(h_\Theta(x),y) = \begin{matrix} 1 & \mbox{if } h_\Theta(x) \geq 0.5\ and\ y = 0\ or\ h_\Theta(x) < 0.5\ and\ y = 1\newline 0 & \mbox otherwise \end{matrix}$

This gives us a binary 0 or 1 error result based on a misclassification. The average test error for the test set is:

$Test Error=\dfrac{1}{m_{test}} \sum^{m_{test}}_{i=1} err(h_\Theta(x^{(i)}_{test}), y^{(i)}_{test})$

This gives us the proportion of the test data that was misclassified.


## Choosing the regulation parameter λ
1. A high λ Under-fits
2. A low λ overfits
3. Selecting a λ, we need to test and compare with $J_{train}(θ)$ and $J_{cv}(θ)$
   1. Create a list of lambdas (i.e. λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24});
   2. Create a set of models with different degrees or any other variants.
   3. Iterate through the λs and for each λ go through all the models to learn some Θ.
   4. Compute the cross validation error using the learned Θ (computed with λ) on the $J_{CV}(\Theta)$ without regularization or λ = 0.
   5. Select the best combo that produces the lowest error on the cross validation set.
   6. Using the best combo Θ and λ, apply it on $J_{test}(\Theta)$ to see if it has a good generalization of the problem.

##Learning Curves

Training an algorithm on a very few number of data points (such as 1, 2 or 3) will easily have 0 errors because we can always find a quadratic curve that touches exactly those number of points. Hence:

* As the training set gets larger, the error for a quadratic function increases
* The error value will plateau out after a certain m, or training set size.

# Data for Machine Learning
The study of the training set size on the Algorithm [^Banko and Brill, 2001]
